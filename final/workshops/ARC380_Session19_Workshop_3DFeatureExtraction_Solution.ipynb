{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARC 380 / CEE 380 â€“ Introduction to Robotics for Digital Fabrication\n",
    "## Session 19 Workshop\n",
    "Princeton University, Spring 2024\n",
    "\n",
    "Professor: Arash Adel | Assistant-in-Instruction: Daniel Ruan\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open3D documentation: https://www.open3d.org/docs/release/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scipy\n",
    "from scipy.cluster.vq import kmeans2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Review: Point Cloud Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be reusing the point cloud from the previous workshop. Before segmenting, we want to run through the same filtering steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded point cloud has 325101 points.\n"
     ]
    }
   ],
   "source": [
    "# Import workshop point cloud\n",
    "pcd = o3d.io.read_point_cloud(\"example_pcd.ply\")\n",
    "\n",
    "print(f'Loaded point cloud has {len(pcd.points)} points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled point cloud has 231940 points.\n"
     ]
    }
   ],
   "source": [
    "# Downsample the point cloud using voxel grid\n",
    "voxel_size = 0.001   # Meters\n",
    "down_pcd = pcd.voxel_down_sample(voxel_size=voxel_size)\n",
    "print(f'Downsampled point cloud has {len(down_pcd.points)} points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered point cloud has 101980 points.\n"
     ]
    }
   ],
   "source": [
    "# Remove points beyond a certain z distance from the camera\n",
    "max_distance = 0.5   # Meters\n",
    "\n",
    "np_down_pcd = np.asarray(down_pcd.points)\n",
    "within_dist_idx = np.where(np.abs(np_down_pcd[:, 2]) < max_distance)[0]\n",
    "filtered_pcd = down_pcd.select_by_index(within_dist_idx)\n",
    "\n",
    "print(f'Filtered point cloud has {len(filtered_pcd.points)} points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier removed point cloud has 99188 points.\n"
     ]
    }
   ],
   "source": [
    "# Remove outlier points using statistical outlier removal\n",
    "nb_neighbors = 20\n",
    "std_ratio = 2\n",
    "filtered_pcd, idx = filtered_pcd.remove_statistical_outlier(nb_neighbors=nb_neighbors, std_ratio=std_ratio)\n",
    "\n",
    "print(f'Outlier removed point cloud has {len(filtered_pcd.points)} points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize filtered point cloud\n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    "rotation = np.array([[1, 0, 0], [0, -1, 0], [0, 0, -1]])\n",
    "coordinate_frame.rotate(rotation, center=(0, 0, 0))\n",
    "o3d.visualization.draw_geometries([filtered_pcd, coordinate_frame])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Point cloud segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Model-Based Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have prior information about the point cloud, then we can try and fit a model to it. For example, we know that a significant portion of our point cloud is a table, so we can fit a plane and its inliers should correspond with the surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plane model: -0.004938893277066706x + 0.11406548771480494y + 0.9934609563770392z + 0.3009804677684685 = 0\n"
     ]
    }
   ],
   "source": [
    "# Use RANSAC to fit a plane and locate the table surface\n",
    "plane_model, inliers = filtered_pcd.segment_plane(distance_threshold=0.01, ransac_n=3, num_iterations=1000)\n",
    "[a, b, c, d] = plane_model\n",
    "print(f'Plane model: {a}x + {b}y + {c}z + {d} = 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plane inliers point cloud has 97624 points.\n",
      "Plane outliers point cloud has 1564 points.\n"
     ]
    }
   ],
   "source": [
    "# Visualize the inliers of the plane\n",
    "inlier_pcd = filtered_pcd.select_by_index(inliers)\n",
    "inlier_pcd.paint_uniform_color([0, 1, 0])\n",
    "print(f'Plane inliers point cloud has {len(inlier_pcd.points)} points.')\n",
    "\n",
    "outlier_pcd = filtered_pcd.select_by_index(inliers, invert=True)\n",
    "outlier_pcd.paint_uniform_color([1, 0, 0])\n",
    "print(f'Plane outliers point cloud has {len(outlier_pcd.points)} points.')\n",
    "\n",
    "o3d.visualization.draw_geometries([inlier_pcd, outlier_pcd, coordinate_frame])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, however, that the distance threshold can greatly impact our results. If we try using RANSAC again on the outlier point cloud to get one of the block surfaces, we need to utilize a smaller `distance_threshold` value for it to correctly segment the two surfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plane model: -0.01250694030809919x + 0.10503517120711803y + 0.9943898577789403z + 0.24493000956221778 = 0\n",
      "Plane inliers point cloud has 817 points.\n",
      "Plane outliers point cloud has 747 points.\n"
     ]
    }
   ],
   "source": [
    "# Use RANSAC again to try and get one of the block surfaces\n",
    "plane_model_2, inliers_2 = outlier_pcd.segment_plane(distance_threshold=0.002, ransac_n=3, num_iterations=1000)\n",
    "[a, b, c, d] = plane_model_2\n",
    "print(f'Plane model: {a}x + {b}y + {c}z + {d} = 0')\n",
    "\n",
    "# Visualize the inliers of the plane\n",
    "inlier_pcd_2 = outlier_pcd.select_by_index(inliers_2)\n",
    "inlier_pcd_2.paint_uniform_color([0, 1, 0])\n",
    "print(f'Plane inliers point cloud has {len(inlier_pcd_2.points)} points.')\n",
    "\n",
    "outlier_pcd_2 = outlier_pcd.select_by_index(inliers_2, invert=True)\n",
    "outlier_pcd_2.paint_uniform_color([1, 0, 0])\n",
    "print(f'Plane outliers point cloud has {len(outlier_pcd_2.points)} points.')\n",
    "\n",
    "o3d.visualization.draw_geometries([inlier_pcd_2, outlier_pcd_2, coordinate_frame])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also potentially get undesirable results if, for example, we had multiple stacks of blocks that were the same height. RANSAC would fit a plane through each stack, and not properly segment them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Unsupervised Learning Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. K-means clustering\n",
    "\n",
    "We previously used K-means clustering to segment 2D images. When we start getting into higher dimensional spaces, however, K-means clustering does not work as well. For example, we do not have significant variation along the z-axis (height), and so k-means will fail to segment the filtered point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids: \n",
      "[[ 0.00720219 -0.09317704 -0.29230056]\n",
      " [ 0.02533757  0.06009382 -0.30793097]\n",
      " [-0.15747076 -0.00608094 -0.30274659]]\n"
     ]
    }
   ],
   "source": [
    "# Use SciPy K-means clustering to segment the filtered point cloud\n",
    "np_filtered_pcd = np.asarray(filtered_pcd.points)\n",
    "k = 3\n",
    "centroids, labels = kmeans2(np_filtered_pcd, k, iter=100, minit='points')\n",
    "print(f'Centroids: \\n{centroids}')\n",
    "\n",
    "# Visualize the labeled point cloud\n",
    "colors = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "colored_points = colors[labels]\n",
    "colored_pcd = o3d.geometry.PointCloud()\n",
    "colored_pcd.points = o3d.utility.Vector3dVector(np_filtered_pcd)\n",
    "colored_pcd.colors = o3d.utility.Vector3dVector(colored_points)\n",
    "\n",
    "# Create a sphere for each centroid\n",
    "spheres = []\n",
    "for centroid in centroids:\n",
    "    sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.003)\n",
    "    sphere.translate(centroid)\n",
    "    spheres.append(sphere)\n",
    "\n",
    "o3d.visualization.draw_geometries([colored_pcd, coordinate_frame] + spheres)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply k-means clustering after segmenting out the table points (e.g., using RANSAC) will provide better results since the clusters are more clearly separated along all dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids: \n",
      "[[-0.09196176 -0.00650727 -0.28806796]\n",
      " [-0.01521934  0.04918027 -0.25169808]]\n"
     ]
    }
   ],
   "source": [
    "# Use SciPy K-means clustering to segment the outlier point cloud after the first RANSAC\n",
    "np_outlier_pcd = np.asarray(outlier_pcd.points)\n",
    "k = 2   # We know there are two block surfaces\n",
    "centroids_2, labels_2 = kmeans2(np_outlier_pcd, k, iter=100, minit='points')\n",
    "print(f'Centroids: \\n{centroids_2}')\n",
    "\n",
    "# Visualize the labeled point cloud\n",
    "colors_2 = np.array([[1, 0, 0], [0, 1, 0]])\n",
    "colored_points_2 = colors_2[labels_2]\n",
    "colored_pcd_2 = o3d.geometry.PointCloud()\n",
    "colored_pcd_2.points = o3d.utility.Vector3dVector(np_outlier_pcd)\n",
    "colored_pcd_2.colors = o3d.utility.Vector3dVector(colored_points_2)\n",
    "\n",
    "# Create a sphere for each centroid\n",
    "spheres_2 = []\n",
    "for centroid in centroids_2:\n",
    "    sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.002)\n",
    "    sphere.translate(centroid)\n",
    "    spheres_2.append(sphere)\n",
    "\n",
    "o3d.visualization.draw_geometries([colored_pcd_2, coordinate_frame] + spheres_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. DBSCAN\n",
    "\n",
    "DBSCAN stands for Density-Based Spatial Clustering of Applications with Noise. Instead of weighing points equally like in k-means, DBSCAN looks at the density of the point neighborhoods. The more points that are clustered together, the higher its density, and the more likely it is to form a cluster.\n",
    "\n",
    "Unlike k-means, DBSCAN does not require prior knowledge of the number of clusters in the point cloud. The clusters are determined by the epsilon value (`eps` parameter in the Open3D implementation), which is how far apart points can be from their neighborhood.\n",
    "\n",
    "Source: \n",
    "- Ester, Martin, et al. \"A density-based algorithm for discovering clusters in large spatial databases with noise.\" *kdd*. Vol. 96. No. 34. 1996."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 clusters.\n"
     ]
    }
   ],
   "source": [
    "# Basic segmentation of the filtered point cloud using DBSCAN clustering\n",
    "labels = filtered_pcd.cluster_dbscan(eps=0.005, min_points=10, print_progress=True)\n",
    "labels = np.asarray(labels)\n",
    "print(f'Found {len(np.unique(labels))} clusters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the centroids and generate spheres for visualization\n",
    "dbscan_centroids = []\n",
    "dbscan_spheres = []\n",
    "for label in np.unique(labels):\n",
    "    cluster = filtered_pcd.select_by_index(np.where(labels == label)[0])\n",
    "    #print(cluster)\n",
    "    centroid = np.asarray(cluster.get_center())\n",
    "    dbscan_centroids.append(centroid)\n",
    "\n",
    "    sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.002)\n",
    "    sphere.translate(centroid)\n",
    "    dbscan_spheres.append(sphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters in different colors\n",
    "dbscan_clusters = []\n",
    "\n",
    "for i in range(len(np.unique(labels))):\n",
    "    cluster = filtered_pcd.select_by_index(np.where(labels == i)[0])\n",
    "    cluster.paint_uniform_color(np.random.rand(3))\n",
    "    dbscan_clusters.append(cluster)\n",
    "\n",
    "o3d.visualization.draw_geometries(dbscan_clusters + dbscan_spheres + [coordinate_frame])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. 3D Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the segmentation methods, we may already have some feature information about the point cloud.\n",
    "\n",
    "For example, RANSAC plane segmentation will give us the surface normal vector, while k-means will give us the centroids.\n",
    "\n",
    "We are primarily interested in the poses of each block (i.e., the centroid of the top surface where the vacuum gripper will attach), and the orientations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Principal Component Analysis\n",
    "\n",
    "Recall that for 2D images, we used moments to compute various measures about segmented regions. We can theoretically do the same for point clouds; however, it will not be as informative. This is because our point cloud only contains (some) points from the surface of the object, and not any interior points, and so analysis of the distribution of points (especially in higher dimensions) becomes less intuitive.\n",
    "\n",
    "We can instead use Principal Component Analysis (PCA) to determine the principal axes of a cluster. PCA originates from statistics, and is used to identify correlations (i.e., variance) in a data set. We expect that the long axis of our block to match the direction of greatest spread (i.e., largest variance) of our point cloud cluster.\n",
    "\n",
    "Imagine we fit an ellipsoid to the cluster. In 3D space, there will be 3 principal axes, which correspond to the orthogonal vectors along the ellipsoid's length, width, and height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One method for performing PCA is using Singular Value Decomposition (SVD):\n",
    "\n",
    "$$\\mathbf{A} = \\mathbf{U\\Sigma V}^\\top$$\n",
    "\n",
    "Recall that we previously used SVD for calculating the \"average\" 3D rotation transformation for the Iterative Closest Point (ICP) algorithm. Here, we are only interested in the columns of $\\mathbf{V}$, which are the right singular vectors, and correspond to the principal components of $\\mathbf{A}$, the covariance matrix of our point cloud.\n",
    "\n",
    "There are other methods for performing PCA, but SVD is widely used because it is efficient to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the covariance matrix $\\mathbf{A}$, we first center the point cloud on the cluster centroid (mean) to remove bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [-0.01521934  0.04918027 -0.25169808]\n",
      "Cluster shape: (817, 3)\n"
     ]
    }
   ],
   "source": [
    "# Potentially change the index here if the chosen cluster is the table surface (we can use size information to determine this, for example)\n",
    "cluster = dbscan_clusters[1]\n",
    "\n",
    "# Center the cluster points around the mean\n",
    "points = np.asarray(cluster.points)\n",
    "mean = np.mean(points, axis=0)\n",
    "centered_points = points - mean\n",
    "\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Cluster shape: {centered_points.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By convention, each row of our input matrix should be a variable that we are interested in computing the covariance with. In our case, we want to find the covariance along the x, y, and z axes, which are currently the columns of the point cloud (i.e., it currently has shape (N, 3)). As such, we need to transpose the point cloud first before computing the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix: \n",
      "[[ 1.63279010e-04 -1.86797076e-05  4.02673769e-06]\n",
      " [-1.86797076e-05  2.79837358e-05 -3.19080333e-06]\n",
      " [ 4.02673769e-06 -3.19080333e-06  5.04822075e-07]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the covariance matrix of the cluster\n",
    "cov = np.cov(centered_points.T)\n",
    "\n",
    "print(f'Covariance matrix: \\n{cov}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now proceed with SVD to compute the principal axes. Remember that SVD gives us the transpose $\\mathbf{V}^\\top$, so we need to transpose it back to get $\\mathbf{V}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular values: [1.65928743e-04 2.57230027e-05 1.15822125e-07]\n",
      "Right singular vectors (columns of V): \n",
      "[[-0.9905198  -0.13680362 -0.01246182]\n",
      " [ 0.13474824 -0.9852479   0.10549643]\n",
      " [-0.02671028  0.10281709  0.99434159]]\n"
     ]
    }
   ],
   "source": [
    "# Perform SVD on the covariance matrix\n",
    "u, sigma, v_transpose = np.linalg.svd(cov)\n",
    "\n",
    "v = v_transpose.T   # Transpose to get the right singular vectors\n",
    "\n",
    "print(f'Singular values: {sigma}')\n",
    "print(f'Right singular vectors (columns of V): \\n{v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the principal axes correspond with the singular values. The largest singular value corresponds to the first principal axis (the 'length' of the ellipsoid), and so on.\n",
    "\n",
    "I.e., if the first singular value in $\\mathbf{\\Sigma}$ is the largest, then the first column in $\\mathbf{V}$ is the largest principal axis, which in our case you can imagine as the 'length' of the fit ellipsoid. The smallest singular value will correspond to the 'height' of the ellipsoid, or the normal vector of the surface.\n",
    "\n",
    "By default, NumPy's SVD function will sort the singular values in descending order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the principal axes by creating a coordinate frame centered at the cluster mean, and rotate it by $\\mathbf{V}$ (remember that $\\mathbf{V}$ is orthonormal, i.e., a rotation matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cluster with its principal axes\n",
    "cluster_axes = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.05, origin=mean)\n",
    "cluster_axes.rotate(v, center=mean)\n",
    "\n",
    "o3d.visualization.draw_geometries([cluster, cluster_axes, coordinate_frame])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cluster mean and principal axes give us enough information to construct the pickup frame for the block relative to the camera.\n",
    "\n",
    "To transform it to the world frame, you can use the same techniques from Assignment 5 to localize the camera using the image, fiducial markers, and taught points, then apply that transformation to the pickup frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional resources:**\n",
    "- StatQuest (YouTube):\n",
    "  - StatQuest: K-means clustering - https://www.youtube.com/watch?v=4b5d3muPQmA\n",
    "  - Clustering with DBSCAN, Clearly Explained!!! - https://www.youtube.com/watch?v=RDZUdRSDOok\n",
    "  - StatQuest: Principal Component Analysis (PCA), Step-by-Step - https://www.youtube.com/watch?v=FgakZw6K1QQ\n",
    "- Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. (2013). An introduction to statistical learning : with applications in Python. New York: Springer.\n",
    "  - https://www.statlearning.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc380",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
